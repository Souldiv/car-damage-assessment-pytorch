{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../car_dam/data3a/\"\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(256),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor()])\n",
    "\n",
    "train_data = datasets.ImageFolder(data_dir + '/training', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/validation', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet152(pretrained=True)\n",
    "fc_in_size = model.fc.in_features\n",
    "model.fc = nn.Sequential(OrderedDict([('fc1', nn.Linear(fc_in_size, 1024)),\n",
    "                                      ('dropout2', nn.Dropout(0.5)),\n",
    "                                      ('relu2', nn.ReLU()),\n",
    "                                      ('fc2', nn.Linear(1024, 3)),\n",
    "                                      ('output', nn.LogSoftmax(dim=1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 2048])\n",
      "torch.Size([1024])\n",
      "torch.Size([3, 1024])\n",
      "torch.Size([3])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    if n.split('.')[0] == 'fc':\n",
    "        pass\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "\n",
    "count = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        print(p.size())\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        output = model.forward(images.cuda())\n",
    "        labels = labels.type(torch.LongTensor).cuda()\n",
    "        test_loss += criterion(output, labels).item()\n",
    "    \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/100..  Training Loss: 0.6459..  valid Loss: 0.7102.. \n",
      "Epoch: 3/100..  Training Loss: 0.6182..  valid Loss: 0.7192.. \n",
      "Epoch: 4/100..  Training Loss: 0.6109..  valid Loss: 0.7853.. \n",
      "Epoch: 5/100..  Training Loss: 0.6169..  valid Loss: 0.7909.. \n",
      "Epoch: 7/100..  Training Loss: 0.5978..  valid Loss: 0.9134.. \n",
      "Epoch: 8/100..  Training Loss: 0.6257..  valid Loss: 0.9312.. \n",
      "Epoch: 9/100..  Training Loss: 0.5913..  valid Loss: 0.7699.. \n",
      "Epoch: 10/100..  Training Loss: 0.5904..  valid Loss: 0.7873.. \n",
      "Epoch: 12/100..  Training Loss: 0.5582..  valid Loss: 0.8270.. \n",
      "Epoch: 13/100..  Training Loss: 0.5934..  valid Loss: 0.7789.. \n",
      "Epoch: 14/100..  Training Loss: 0.5821..  valid Loss: 0.6804.. \n",
      "Epoch: 15/100..  Training Loss: 0.6277..  valid Loss: 0.6350.. \n",
      "Epoch: 17/100..  Training Loss: 0.6199..  valid Loss: 0.6377.. \n",
      "Epoch: 18/100..  Training Loss: 0.6319..  valid Loss: 0.6544.. \n",
      "Epoch: 19/100..  Training Loss: 0.5570..  valid Loss: 0.7141.. \n",
      "Epoch: 20/100..  Training Loss: 0.5693..  valid Loss: 0.6972.. \n",
      "Epoch: 22/100..  Training Loss: 0.5784..  valid Loss: 0.7490.. \n",
      "Epoch: 23/100..  Training Loss: 0.5853..  valid Loss: 0.7418.. \n",
      "Epoch: 24/100..  Training Loss: 0.5740..  valid Loss: 0.7907.. \n",
      "Epoch: 25/100..  Training Loss: 0.5367..  valid Loss: 0.7833.. \n",
      "Epoch: 27/100..  Training Loss: 0.5140..  valid Loss: 0.8624.. \n",
      "Epoch: 28/100..  Training Loss: 0.5684..  valid Loss: 0.7946.. \n",
      "Epoch: 29/100..  Training Loss: 0.5648..  valid Loss: 0.7883.. \n",
      "Epoch: 30/100..  Training Loss: 0.5458..  valid Loss: 0.7297.. \n",
      "Epoch: 32/100..  Training Loss: 0.5481..  valid Loss: 0.7109.. \n",
      "Epoch: 33/100..  Training Loss: 0.5420..  valid Loss: 0.7085.. \n",
      "Epoch: 34/100..  Training Loss: 0.5190..  valid Loss: 0.7629.. \n",
      "Epoch: 35/100..  Training Loss: 0.4929..  valid Loss: 0.7701.. \n",
      "Epoch: 37/100..  Training Loss: 0.5242..  valid Loss: 0.8623.. \n",
      "Epoch: 38/100..  Training Loss: 0.5255..  valid Loss: 0.6996.. \n",
      "Epoch: 39/100..  Training Loss: 0.5355..  valid Loss: 0.7381.. \n",
      "Epoch: 40/100..  Training Loss: 0.5240..  valid Loss: 0.7641.. \n",
      "Epoch: 42/100..  Training Loss: 0.5036..  valid Loss: 0.8097.. \n",
      "Epoch: 43/100..  Training Loss: 0.4921..  valid Loss: 0.7878.. \n",
      "Epoch: 44/100..  Training Loss: 0.4955..  valid Loss: 0.8930.. \n",
      "Epoch: 45/100..  Training Loss: 0.5197..  valid Loss: 0.7631.. \n",
      "Epoch: 47/100..  Training Loss: 0.5264..  valid Loss: 0.7502.. \n",
      "Epoch: 48/100..  Training Loss: 0.5084..  valid Loss: 0.7794.. \n",
      "Epoch: 49/100..  Training Loss: 0.4831..  valid Loss: 0.8384.. \n",
      "Epoch: 50/100..  Training Loss: 0.4861..  valid Loss: 0.7315.. \n",
      "Epoch: 52/100..  Training Loss: 0.4895..  valid Loss: 0.7890.. \n",
      "Epoch: 53/100..  Training Loss: 0.5032..  valid Loss: 0.7448.. \n",
      "Epoch: 54/100..  Training Loss: 0.4846..  valid Loss: 0.7375.. \n",
      "Epoch: 55/100..  Training Loss: 0.4433..  valid Loss: 0.7025.. \n",
      "Epoch: 57/100..  Training Loss: 0.4470..  valid Loss: 0.8006.. \n",
      "Epoch: 58/100..  Training Loss: 0.4528..  valid Loss: 0.8092.. \n",
      "Epoch: 59/100..  Training Loss: 0.4615..  valid Loss: 0.8368.. \n",
      "Epoch: 60/100..  Training Loss: 0.4835..  valid Loss: 0.9078.. \n",
      "Epoch: 62/100..  Training Loss: 0.4759..  valid Loss: 0.9793.. \n",
      "Epoch: 63/100..  Training Loss: 0.4994..  valid Loss: 0.9020.. \n",
      "Epoch: 64/100..  Training Loss: 0.4680..  valid Loss: 0.8637.. \n",
      "Epoch: 65/100..  Training Loss: 0.4684..  valid Loss: 0.9304.. \n",
      "Epoch: 67/100..  Training Loss: 0.4640..  valid Loss: 0.9089.. \n",
      "Epoch: 68/100..  Training Loss: 0.4847..  valid Loss: 0.8152.. \n",
      "Epoch: 69/100..  Training Loss: 0.4265..  valid Loss: 0.8491.. \n",
      "Epoch: 70/100..  Training Loss: 0.4557..  valid Loss: 0.8121.. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3fa0158151f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "SAVE_PATH = \"../Models/3_Classify/\"\n",
    "\n",
    "# writer = SummaryWriter()\n",
    "model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=4e-4)\n",
    "if checkpoint_run:\n",
    "    optimizer.load_state_dict(inf['optimizer_state_dict'])\n",
    "\n",
    "best_train_loss = 0.7\n",
    "best_val_loss = 0.7\n",
    "\n",
    "# scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[5, 15, 25, 40, 50], gamma=0.1)\n",
    "\n",
    "num_epochs = 100\n",
    "running_loss = 0\n",
    "steps = 0\n",
    "print_every = 10\n",
    "log_every = 10\n",
    "log_step = 0\n",
    "\n",
    "\n",
    "log_every = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "#     scheduler.step()\n",
    "    for data_ in trainloader:\n",
    "        steps += 1\n",
    "        img, bbox = data_\n",
    "        \n",
    "        img = img.cuda()\n",
    "        target = bbox.type(torch.LongTensor).cuda()\n",
    "        \n",
    "        output = model(img)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % log_every == 0:\n",
    "            log_step += 1\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid_loss = validation(model, testloader, criterion)\n",
    "            model.train()\n",
    "            \n",
    "            train_loss = running_loss/log_every\n",
    "            val_loss = valid_loss/len(testloader)\n",
    "            \n",
    "#             writer.add_scalar('Training Loss', train_loss, log_step)\n",
    "#             writer.add_scalar('Validation Loss', val_loss, log_step)\n",
    "#             writer.add_scalar('Learning rate', optimizer.state_dict()['param_groups'][0]['lr'], log_step)\n",
    "            \n",
    "            if val_loss < best_val_loss and train_loss < best_train_loss:\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'train_loss': train_loss,\n",
    "                    'val_loss': val_loss\n",
    "            }, SAVE_PATH + \"resnet152_3_epoch{}_step{}.pkl\".format(epoch, steps))\n",
    "                best_train_loss = train_loss\n",
    "                best_val_loss = val_loss\n",
    "            running_loss = 0\n",
    "            \n",
    "        if steps % print_every == 0:\n",
    "            print(\"Epoch: {}/{}.. \".format(epoch+1, num_epochs),\n",
    "                  \"Training Loss: {:.4f}.. \".format(train_loss),\n",
    "                  \"valid Loss: {:.4f}.. \".format(val_loss))\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "y_pred = list()\n",
    "y_true = list()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, op in iter(trainloader):\n",
    "        k = model.forward(imgs.cuda())\n",
    "        y_pred.extend(list(np.argmax(k.cpu().data.numpy(), axis=1)))\n",
    "        y_true.extend(op.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD8CAYAAABJsn7AAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCQQJWARkUCUgEVEAvl/W6BDg7uh1jkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc2c2f71748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_pred=y_pred, y_true=y_true)\n",
    "_ = sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       278\n",
      "           1       0.82      0.71      0.76       315\n",
      "           2       0.87      0.89      0.88       386\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       979\n",
      "   macro avg       0.83      0.83      0.83       979\n",
      "weighted avg       0.83      0.83      0.83       979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=y_true, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "pt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
